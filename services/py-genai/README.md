# NicheExplorer GenAI Service

The GenAI service is the AI-powered engine of NicheExplorer, focused on data acquisition and embedding generation. It fetches research papers from ArXiv, classifies user queries, and generates high-quality semantic embeddings using Google Gemini AI. Embeddings are cached in ChromaDB for efficient retrieval by the Topic Discovery service.

---

## 1 Â· Responsibilities in one glance
* **Query classification** â€“ determines appropriate ArXiv categories from natural language queries
* **ArXiv integration** â€“ fetches research papers by category using the official ArXiv API
* **Embedding generation** â€“ creates semantic embeddings using Google Gemini AI API
* **ChromaDB caching** â€“ stores and retrieves embeddings efficiently with batch processing
* **REST endpoints** â€“ exposes `/classify`, `/arxiv/search`, `/embed`, and `/embed-batch` for the microservices architecture

```
Query â†’ Classification â†’ ArXiv Fetch â†’ Embedding Generation â†’ ChromaDB Cache â†’ Topic Discovery Service
```

### **Service Structure**
```
src/
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ routers/                # API endpoint handlers
â”‚   â”œâ”€â”€ arxiv.py           # ArXiv search and category endpoints
â”‚   â”œâ”€â”€ classification.py   # Query classification
â”‚   â””â”€â”€ embedding.py       # Vector embedding operations
â”œâ”€â”€ services/               # Core AI services
â”‚   â”œâ”€â”€ arxiv_service.py           # ArXiv API integration
â”‚   â”œâ”€â”€ embedding_service.py      # Google Gemini embeddings + ChromaDB
â”‚   â”œâ”€â”€ google_client.py          # Google Gemini API client
â”‚   â””â”€â”€ openweb_client.py         # Open WebUI API integration
â”œâ”€â”€ models/                 # Data models and schemas
â”‚   â””â”€â”€ schemas.py         # Pydantic models for API
â””â”€â”€ config/                 # Configuration management
    â””â”€â”€ settings.py        # Environment and model settings
```

## ðŸ”„ Microservices Integration

> Note â€“ This service focuses on data acquisition and embedding generation. Topic discovery and clustering are handled by the dedicated Topic Discovery service.

---

## 3 Â· Processing pipeline (REST architecture)
1. **Classification** â€“ Analyze natural language queries to determine appropriate ArXiv categories (cs.CV, cs.AI, etc.)
2. **ArXiv Search** â€“ Fetch research papers by category using advanced ArXiv API queries
3. **Batch Embedding** â€“ Generate semantic embeddings for multiple papers efficiently using Google Gemini
4. **ChromaDB Caching** â€“ Store embeddings with paper IDs for fast retrieval and reuse
5. **API Response** â€“ Return structured data to Java API server or Topic Discovery service
6. **Embedding Retrieval** â€“ Serve cached embeddings to Topic Discovery service for clustering

---

## 4 Â· Configuration & environment
* `GOOGLE_API_KEY` â€“ optional; unlocks Gemini embeddings.  If missing the service silently switches to the local Sentence-Transformer model.
* `CHAIR_API_KEY` - necessary to use the models hosted by the chair. Currently this is only utilized for the /classify endpoint.
* Processing limits such as `MAX_ARTICLES_PER_REQUEST` and `MIN_TREND_FREQUENCY` are centralised in `config/settings.py` and can be tuned without code changes.

---

## 5 Â· Public endpoints (no payloads shown)
1. **POST `/classify`** â€“ determines if query is "research" or "community" and suggests appropriate ArXiv category
2. **POST `/arxiv/search`** â€“ fetches research papers by ArXiv category or advanced query
3. **POST `/embed`** â€“ generates single embedding for text using Google Gemini
4. **POST `/embed-batch`** â€“ efficient batch embedding generation with ChromaDB caching
5. **POST `/embeddings-by-ids`** â€“ retrieves cached embeddings by paper IDs for Topic Discovery service

---

This document intentionally omits implementation code so it can be pasted anywhere without syntax-highlighting noise while still giving developers a clear picture of how the GenAI layer feeds the rest of NicheExplorer.
